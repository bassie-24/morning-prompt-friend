import { getPlatformInfo, platformLog, isFeatureAvailable } from '@/utils/platformUtils';
import { storageService, UserInstruction } from '@/utils/storage';
import { ChatCompletionMessageParam } from 'openai/resources/chat/completions.mjs';
import OpenAI from "openai";
import { webSearchService } from '@/services/WebSearchService';

export interface SpeechRecognitionOptions {
  language?: string;
  continuous?: boolean;
  interimResults?: boolean;
  maxAlternatives?: number;
}

export interface SpeechSynthesisOptions {
  text: string;
  language?: string;
  rate?: number;
  pitch?: number;
  volume?: number;
}

export interface SpeechRecognitionResult {
  transcript: string;
  confidence: number;
  isFinal: boolean;
}

export class CapacitorSpeechService {
  private static instance: CapacitorSpeechService;
  private recognition: any | null = null;
  private synthesis: SpeechSynthesis | null = null;
  private isListening = false;
  private isSpeaking = false;
  private currentConversation: Array<{ role: 'user' | 'assistant'; content: string; timestamp: string }> = [];

  // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
  private onResultCallback?: (result: SpeechRecognitionResult) => void;
  private onEndCallback?: () => void;
  private onErrorCallback?: (error: string) => void;
  private onStartCallback?: () => void;

  private constructor() {
    this.initializeServices();
  }

  public static getInstance(): CapacitorSpeechService {
    if (!CapacitorSpeechService.instance) {
      CapacitorSpeechService.instance = new CapacitorSpeechService();
    }
    return CapacitorSpeechService.instance;
  }

  /**
   * éŸ³å£°ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
   */
  private initializeServices(): void {
    const platform = getPlatformInfo();
    
    try {
      // Web Speech API (å…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§åˆ©ç”¨å¯èƒ½)
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognitionClass = window.SpeechRecognition || window.webkitSpeechRecognition;
        this.recognition = new SpeechRecognitionClass();
        platformLog('Speech Recognition initialized');
      }

      if ('speechSynthesis' in window) {
        this.synthesis = window.speechSynthesis;
        platformLog('Speech Synthesis initialized');
      }

      // Capacitorç’°å¢ƒã§ã®è¿½åŠ åˆæœŸåŒ–ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
      if (platform.isNative) {
        this.initializeNativeSpeechFeatures();
      }

    } catch (error) {
      platformLog('Failed to initialize speech services:', error);
    }
  }

  /**
   * ãƒã‚¤ãƒ†ã‚£ãƒ–éŸ³å£°æ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
   */
  private async initializeNativeSpeechFeatures(): Promise<void> {
    try {
      // å°†æ¥çš„ã«Capacitor Speech pluginã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®å®Ÿè£…å ´æ‰€
      platformLog('Native speech features ready for implementation');
    } catch (error) {
      platformLog('Native speech initialization failed:', error);
    }
  }



  /**
   * éŸ³å£°èªè­˜ã®åœæ­¢
   */
  public stopListening(): void {
    if (this.recognition && this.isListening) {
      this.recognition.stop();
      this.isListening = false;
      platformLog('Speech recognition stopped');
    }
  }

  /**
   * SpeechServiceã¨ã®äº’æ›æ€§ã‚’ä¿ã¤ãŸã‚ã®speakï¼ˆPromiseç‰ˆï¼‰
   */
  async speak(text: string): Promise<void> {
    return new Promise((resolve) => {
      if (!this.synthesis) {
        platformLog('Speech synthesis not available');
        resolve();
        return;
      }

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ja-JP';
      utterance.rate = 0.9;
      utterance.pitch = 1.1;
      
      utterance.onend = () => {
        this.isSpeaking = false;
        resolve();
      };

      utterance.onerror = () => {
        this.isSpeaking = false;
        resolve();
      };

      utterance.onstart = () => {
        this.isSpeaking = true;
      };

      this.synthesis.speak(utterance);
    });
  }

  /**
   * éŸ³å£°åˆæˆã®åœæ­¢
   */
  public stopSpeaking(): void {
    if (this.synthesis && this.isSpeaking) {
      this.synthesis.cancel();
      this.isSpeaking = false;
      platformLog('Speech synthesis cancelled');
    }
  }

  /**
   * éŸ³å£°èªè­˜ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã®è¨­å®š
   */
  private setupRecognitionListeners(): void {
    if (!this.recognition) return;

    this.recognition.onstart = () => {
      platformLog('Speech recognition service started');
      this.onStartCallback?.();
    };

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      const results = Array.from(event.results);
      const latestResult = results[results.length - 1];
      
      if (latestResult) {
        const transcript = latestResult[0].transcript.trim();
        const confidence = latestResult[0].confidence;
        const isFinal = latestResult.isFinal;

        const result: SpeechRecognitionResult = {
          transcript,
          confidence,
          isFinal
        };

        platformLog(`Speech result: "${transcript}" (confidence: ${confidence}, final: ${isFinal})`);
        this.onResultCallback?.(result);
      }
    };

    this.recognition.onend = () => {
      this.isListening = false;
      platformLog('Speech recognition ended');
      this.onEndCallback?.();
    };

    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      this.isListening = false;
      const errorMessage = `Speech recognition error: ${event.error}`;
      platformLog(errorMessage);
      this.onErrorCallback?.(errorMessage);
    };

    this.recognition.onnomatch = () => {
      platformLog('Speech recognition: no match found');
    };

    this.recognition.onsoundstart = () => {
      platformLog('Speech recognition: sound detected');
    };

    this.recognition.onsoundend = () => {
      platformLog('Speech recognition: sound ended');
    };
  }

  /**
   * ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
   */
  public setEventHandlers(handlers: {
    onResult?: (result: SpeechRecognitionResult) => void;
    onEnd?: () => void;
    onError?: (error: string) => void;
    onStart?: () => void;
  }): void {
    this.onResultCallback = handlers.onResult;
    this.onEndCallback = handlers.onEnd;
    this.onErrorCallback = handlers.onError;
    this.onStartCallback = handlers.onStart;
  }

  /**
   * åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ä¸€è¦§å–å¾—
   */
  public getAvailableVoices(): SpeechSynthesisVoice[] {
    if (!this.synthesis) return [];
    
    return this.synthesis.getVoices().filter(voice => 
      voice.lang.startsWith('ja') || voice.lang.startsWith('en')
    );
  }

  /**
   * éŸ³å£°èªè­˜çŠ¶æ…‹ã®å–å¾—
   */
  public get isRecognitionActive(): boolean {
    return this.isListening;
  }

  /**
   * éŸ³å£°åˆæˆçŠ¶æ…‹ã®å–å¾—
   */
  public get isSynthesisActive(): boolean {
    return this.isSpeaking;
  }

  /**
   * éŸ³å£°æ©Ÿèƒ½ã®åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
   */
  public static isAvailable(): boolean {
    const hasRecognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
    const hasSynthesis = 'speechSynthesis' in window;
    
    return hasRecognition && hasSynthesis;
  }

  /**
   * ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æƒ…å ±ä»˜ãã®ãƒ­ã‚°
   */
  private log(message: string, data?: any): void {
    platformLog(`[SpeechService] ${message}`, data);
  }

  /**
   * SpeechServiceã¨ã®äº’æ›æ€§ã‚’ä¿ã¤ãŸã‚ã®Promiseãƒ™ãƒ¼ã‚¹ã®éŸ³å£°èªè­˜
   */
  async startListening(): Promise<string> {
    platformLog('=== Capacitor startListening ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ ===');
    
    return new Promise((resolve, reject) => {
      if (!this.recognition) {
        platformLog('éŸ³å£°èªè­˜ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“');
        reject(new Error('éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“'));
        return;
      }

      // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®š
      this.setEventHandlers({
        onResult: (result) => {
          if (result.isFinal) {
            platformLog(`èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: ${result.transcript}`);
            resolve(result.transcript);
          }
        },
        onError: (error) => {
          platformLog(`éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${error}`);
          reject(new Error(error));
        },
        onStart: () => {
          platformLog('éŸ³å£°èªè­˜ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸ');
        }
      });

      // éŸ³å£°èªè­˜é–‹å§‹
      this.startRecognition().catch(reject);
    });
  }

  /**
   * SpeechServiceã¨ã®äº’æ›æ€§ã‚’ä¿ã¤ãŸã‚ã®OpenAI APIçµ±åˆ
   */
  async sendToOpenAI(message: string, instructions: UserInstruction[]): Promise<string> {
    const rawApiKey = storageService.getOpenAIKey();
    platformLog('ğŸ”‘ Raw API Key from storage:', rawApiKey ? `${rawApiKey.substring(0, 10)}...${rawApiKey.substring(rawApiKey.length-10)}` : 'null');
    
    if (!rawApiKey) {
      throw new Error('OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“');
    }
    
    const apiKey = rawApiKey.trim();
    const basicFormat = apiKey.startsWith('sk-') && apiKey.length > 10;
    
    if (!basicFormat) {
      throw new Error('APIã‚­ãƒ¼ã¯ "sk-" ã§å§‹ã¾ã‚Šã€10æ–‡å­—ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚');
    }

    const client = new OpenAI({
      apiKey: apiKey,
      dangerouslyAllowBrowser: true, 
    });
    
    const planInfo = storageService.getUserPlanInfo();
    const systemPrompt = this.buildSystemPrompt(instructions);
    
    const messages: ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      ...this.currentConversation,
      { role: 'user', content: message }
    ];

    platformLog(`OpenAI APIã«é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (${planInfo.planDisplayName} - ${planInfo.modelUsed}):`, messages);

    try {
      const activeInstructions = instructions.filter(inst => inst.isActive);
      const useWebSearch = planInfo.hasSearch && activeInstructions.some(inst => inst.useWebSearch);
      
      let aiResponse: string;

      if (useWebSearch) {
        platformLog('ğŸ” Responses APIã§Webæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™');
        
        const response = await client.responses.create({
          model: planInfo.modelUsed,
          tools: [
            { type: "web_search_preview" },
          ],
          input: messages.map(msg => `${msg.role}: ${msg.content}`).join('\n'),
        });

        platformLog('ğŸ”„ Responses API ãƒ¬ã‚¹ãƒãƒ³ã‚¹:', response);
        aiResponse = response.output_text || 'Responses APIã‹ã‚‰æœ‰åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ';
      } else {
        platformLog('ğŸ’¬ é€šå¸¸ã®Chat Completions APIã‚’ä½¿ç”¨ã—ã¾ã™');
        
        const response = await client.chat.completions.create({
          model: planInfo.modelUsed,
          messages: messages,
          max_tokens: 500,
          temperature: 0.7,
        });

        aiResponse = response.choices[0].message.content || "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";
      }

      // ä¼šè©±å±¥æ­´ã‚’æ›´æ–°
      this.currentConversation.push(
        { role: 'user', content: message, timestamp: new Date().toISOString() },
        { role: 'assistant', content: aiResponse, timestamp: new Date().toISOString() }
      );

      return aiResponse;
    } catch (error) {
      platformLog('OpenAI API ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }

  /**
   * ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
   */
  private buildSystemPrompt(instructions: UserInstruction[], hasExternalData: boolean = false): string {
    const activeInstructions = instructions
      .filter(inst => inst.isActive)
      .sort((a, b) => a.order - b.order)
      .map(inst => {
        let instructionText = `${inst.title}: ${inst.content}`;
        if (inst.useWebSearch) {
          instructionText += ' (å¿…è¦ã«å¿œã˜ã¦æœ€æ–°æƒ…å ±ã‚’æ¤œç´¢ã—ã¦å›ç­”)';
        }
        return instructionText;
      })
      .join('\n');

    const externalDataInfo = hasExternalData ? `

ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ—ãƒ©ãƒ³é™å®šæ©Ÿèƒ½ï¼š
- å¿…è¦ã«å¿œã˜ã¦ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€å¤©æ°—äºˆå ±ã€æ—¥ä»˜/æ™‚åˆ»æƒ…å ±ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™
- æœã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒã‚ã‚Œã°ç©æ¥µçš„ã«æä¾›ã—ã¦ãã ã•ã„
- ãŸã ã—ã€å®Ÿéš›ã®å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚ã€ä¸€èˆ¬çš„ãªæƒ…å ±ã‚„æ¨æ¸¬ã§å›ç­”ã—ã¦ãã ã•ã„` : '';

    return `ã‚ãªãŸã¯æœã®ç›®è¦šã‚ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœã®è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®æŒ‡ç¤ºå†…å®¹ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

${activeInstructions}

é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
1. å„ªã—ãã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§è©±ã—ã¦ãã ã•ã„
2. ä¸€åº¦ã«ä¸€ã¤ã®æŒ‡ç¤ºã‚’å‡ºã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ±å‘Šã‚’å¾…ã£ã¦ãã ã•ã„
3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡ç¤ºã‚’å®Œäº†ã—ãŸã‚‰ã€æ¬¡ã®æŒ‡ç¤ºã«é€²ã‚“ã§ãã ã•ã„
4. åŠ±ã¾ã—ã®è¨€è‘‰ã‚’é©åº¦ã«å…¥ã‚Œã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶­æŒã—ã¦ãã ã•ã„
5. å›ç­”ã¯ç°¡æ½”ã«ã€1-2æ–‡ç¨‹åº¦ã«ã—ã¦ãã ã•ã„
6. å…¨ã¦ã®æŒ‡ç¤ºãŒå®Œäº†ã—ãŸã‚‰ã€ãŠç–²ã‚Œæ§˜ã§ã—ãŸã¨ä¼ãˆã¦çµ‚äº†ã—ã¦ãã ã•ã„
7. webæ¤œç´¢æ©Ÿèƒ½ãŒæœ‰åŠ¹ãªæŒ‡ç¤ºã§ã¯ã€å¿…è¦ã«å¿œã˜ã¦æœ€æ–°ã®æƒ…å ±ã‚’æ¤œç´¢ã—ã¦å›ç­”ã—ã¦ãã ã•ã„

æœ€åˆã®æŒ‡ç¤ºã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ã€‚`;
  }

  /**
   * ä¼šè©±å±¥æ­´ã®å–å¾—
   */
  getConversationHistory() {
    return this.currentConversation;
  }

  /**
   * ä¼šè©±å±¥æ­´ã®ãƒªã‚»ãƒƒãƒˆ
   */
  resetConversation() {
    this.currentConversation = [];
  }

  /**
   * éŸ³å£°èªè­˜çŠ¶æ…‹ã®getterï¼ˆSpeechServiceã¨ã®äº’æ›æ€§ï¼‰
   */
  get listening() {
    return this.isListening;
  }
}

// ã‚°ãƒ­ãƒ¼ãƒãƒ«å‹å®šç¾©ï¼ˆTypeScriptç”¨ï¼‰
declare global {
  interface Window {
    SpeechRecognition: any;
    webkitSpeechRecognition: any;
  }
  
  interface SpeechRecognitionEvent {
    results: SpeechRecognitionResultList;
  }
  
  interface SpeechRecognitionErrorEvent {
    error: string;
  }
}

export default CapacitorSpeechService; 